{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc8966a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ivica Obadic\\PycharmProjects\\EOExplainability\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "print(module_path)\n",
    "from datasets import dataset_utils\n",
    "from datasets import sequence_aggregator\n",
    "from explainability_analysis.visualization_functions import * \n",
    "from explainability_analysis.transformer_analysis import *\n",
    "from explainability_analysis.crop_spectral_signature_analysis import * \n",
    "\n",
    "num_classes = 12\n",
    "shuffle_setting = \"original_sequences\"\n",
    "shuffle_sequences = False\n",
    "max_sequence_length = 144\n",
    "\n",
    "def sort_obs_acq_dates_by_attention(model_root_path):\n",
    "    \n",
    "    predictions_path = os.path.join(model_root_path, \"predictions\")\n",
    "    predicted_vs_true_results = pd.read_csv(os.path.join(predictions_path, \"predicted_vs_true.csv\"))\n",
    "    attn_weights_path = os.path.join(predictions_path, \"attn_weights\", \"postprocessed\")\n",
    "    \n",
    "    total_temporal_attention = summarize_attention_weights_as_feature_embeddings(attn_weights_path, \"layer_0\", summary_fn=\"sum\")\n",
    "    attention_per_obs_acq_date = pd.concat([v for k,v in total_temporal_attention.items()])\n",
    "    \n",
    "    avg_attention_per_obs_acq_date = attention_per_obs_acq_date.mean().sort_values(ascending=False)\n",
    "    avg_attention_per_obs_acq_date = avg_attention_per_obs_acq_date.to_frame()\n",
    "    avg_attention_per_obs_acq_date.index.name=\"DATE\"\n",
    "    avg_attention_per_obs_acq_date.columns=[\"TOTAL_TEMPORAL_ATTENTION\"]\n",
    "    avg_attention_per_obs_acq_date.index = avg_attention_per_obs_acq_date.index.map(lambda x: \"2018-{}-{}\".format(x.split(\"-\")[1], x.split(\"-\")[0]))\n",
    "    avg_attention_per_obs_acq_date.to_csv(os.path.join(attn_weights_path, \"key_attention_dates.csv\"))\n",
    "    return avg_attention_per_obs_acq_date\n",
    "\n",
    "\n",
    "def read_classification_results(classification_results_dir):\n",
    "    classification_results_path = os.path.join(classification_results_dir, \"predictions\", \"classification_metrics.csv\")\n",
    "    if (os.path.exists(classification_results_path)):\n",
    "        classification_data = np.genfromtxt(classification_results_path, delimiter=',', skip_header = 1)\n",
    "        return classification_data[2], classification_data[6]\n",
    "    return None\n",
    "\n",
    "def get_results_with_perc_of_dates(perc_important_dates_results_root_dir):\n",
    "    perc_dates_results = []\n",
    "    for result_dir in os.listdir(perc_important_dates_results_root_dir):\n",
    "        if result_dir.endswith(\"frac_of_dates\"):\n",
    "            result_dir_parts = result_dir.split(\"_\")\n",
    "            frac = float(result_dir_parts[0])\n",
    "            model_results_dir = os.path.join(perc_important_dates_results_root_dir, result_dir, \"obs_aq_date\", \"layers=1,heads=1,emb_dim=128\")\n",
    "            classification_results = read_classification_results(model_results_dir)\n",
    "            if classification_results is not None:\n",
    "                perc_dates_results.append((int(frac * 100), classification_results[0], \"Percentage of Dates\"))\n",
    "    \n",
    "\n",
    "    perc_dates_results = pd.DataFrame(data=perc_dates_results, columns=[\"Percent of observations\", \"Class accuracy\", \"Model type\"])\n",
    "    return perc_dates_results\n",
    "\n",
    "def get_most_important_dates_for_percentage_scores(percentages, perc_dates_results, avg_attention_per_obs_acq_date_orig_model):\n",
    "    result_dfs = []\n",
    "    for perc in percentages:\n",
    "        num_top_n_perc_dates = round((perc / 100.0) * max_sequence_length)\n",
    "        top_n_perc_dates = avg_attention_per_obs_acq_date_orig_model.iloc[0:num_top_n_perc_dates].reset_index()\n",
    "        top_n_perc_dates[\"PERCENTAGE\"] = perc\n",
    "        top_n_perc_dates[\"DATE\"] = pd.to_datetime(top_n_perc_dates[\"DATE\"]).apply(lambda date: date.strftime(\"%m-%d\"))\n",
    "        #top_n_perc_dates[\"DATE\"] = top_n_perc_dates[\"DATE\"].apply(lambda date: date[date.index(\"-\") + 1:])\n",
    "        top_n_perc_dates_with_accuracy = pd.merge(top_n_perc_dates, perc_dates_results, left_on=\"PERCENTAGE\", right_on=\"Percent of observations\")\n",
    "        result_dfs.append(top_n_perc_dates_with_accuracy)\n",
    "    \n",
    "    return pd.concat(result_dfs, ignore_index=True).sort_values(by=\"DATE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c55da207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the attention weights for the 0-th test example\n",
      "Reading the attention weights for the 1000-th test example\n",
      "Reading the attention weights for the 2000-th test example\n",
      "Reading the attention weights for the 3000-th test example\n",
      "Reading the attention weights for the 4000-th test example\n",
      "Reading the attention weights for the 5000-th test example\n",
      "Reading the attention weights for the 6000-th test example\n",
      "Reading the attention weights for the 7000-th test example\n",
      "Reading the attention weights for the 8000-th test example\n",
      "Reading the attention weights for the 9000-th test example\n",
      "Reading the attention weights for the 10000-th test example\n",
      "Reading the attention weights for the 11000-th test example\n",
      "Reading the attention weights for the 12000-th test example\n",
      "Reading the attention weights for the 13000-th test example\n",
      "Reading the attention weights for the 14000-th test example\n",
      "Reading the attention weights for the 15000-th test example\n",
      "Reading the attention weights for the 16000-th test example\n",
      "Reading the attention weights for the 17000-th test example\n"
     ]
    }
   ],
   "source": [
    "dataset_folder = \"C:/Users/datasets/BavarianCrops/\"\n",
    "model_root_path = \"C:/Users/results/{}_classes/{}/right_padding/obs_aq_date/layers=1,heads=1,emb_dim=128/\"\n",
    "model_root_path = model_root_path.format(num_classes, shuffle_setting)\n",
    "\n",
    "avg_attention_per_obs_acq_date_orig_model = sort_obs_acq_dates_by_attention(model_root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbd1e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_model_result = read_classification_results(model_root_path)\n",
    "root_frac_important_dates_results_dir = \"C:/Users/results/12_classes/original_sequences/right_padding/\"\n",
    "perc_dates_results = get_results_with_perc_of_dates(root_frac_important_dates_results_dir)\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(7, 4))\n",
    "sns.scatterplot(data=perc_dates_results, x=\"Percent of observations\", y='Class accuracy', hue=\"Model type\", ax=axs)\n",
    "axs.axhline(y=original_model_result[0], c='red', linestyle='dashed', label=\"Entire Dataset\")\n",
    "axs.legend(loc=\"upper right\")\n",
    "perc_dates_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280b2201",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_important_dates_for_percentage_scores = get_most_important_dates_for_percentage_scores([2, 3, 4, 5, 6, 10], perc_dates_results, avg_attention_per_obs_acq_date_orig_model)\n",
    "fig, axs = plt.subplots(figsize=(8, 5))\n",
    "sns.scatterplot(data=most_important_dates_for_percentage_scores, x=\"DATE\", y='Class accuracy', hue=\"Percent of observations\", ax=axs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
